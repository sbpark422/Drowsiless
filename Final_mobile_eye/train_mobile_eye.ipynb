{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator#, img_to_array, array_to_img\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobilenet_preproc\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "# Load Dataset\n",
    "\n",
    "tb_hist = TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "n_features = 512\n",
    "\n",
    "def preprocess_input(x):\n",
    "    img = x[:,:,::-1]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "\n",
    "def mobilenet_model():\n",
    "    base_model = MobileNet(weights='imagenet', include_top=True, \n",
    "                     input_shape=(224, 224, 3))\n",
    "    base_model.layers.pop()\n",
    "    x = base_model.layers[-1].output\n",
    "    x = Dense(512)(x)\n",
    "    x = Flatten()(x)\n",
    "    #n_classes = Dense(6)(x)\n",
    "    n_classes = Dense(1)(x)\n",
    "    model = Model(input = base_model.input, output = n_classes)\n",
    "    #opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None)\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(\n",
    "        #loss='categorical_crossentropy',\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Preview\n",
    "\n",
    "#shape_used = (100, 100)\n",
    "shape_used = (224, 224)\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "n_patience = 30\n",
    "\n",
    "traingen = ImageDataGenerator(\n",
    "    preprocessing_function = mobilenet_preproc,\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    #zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    zca_whitening=False)\n",
    "            \n",
    "train_generator = traingen.flow_from_directory(\n",
    "    directory='train/',\n",
    "    target_size=shape_used,\n",
    "    batch_size=batch_size,\n",
    "    #class_mode=\"categorical\",\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "validgen = ImageDataGenerator(\n",
    "    preprocessing_function = mobilenet_preproc,\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    #zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    zca_whitening=False)\n",
    "\n",
    "valid_generator = validgen.flow_from_directory(\n",
    "    directory='valid/',\n",
    "    target_size=shape_used,\n",
    "    batch_size=batch_size,\n",
    "    #class_mode=\"categorical\",\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "testgen = ImageDataGenerator(\n",
    "    preprocessing_function = mobilenet_preproc,\n",
    "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    #zoom_range=[0.8,1.2],\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    zca_whitening=False)\n",
    "\n",
    "test_generator = testgen.flow_from_directory(\n",
    "    directory='test/',\n",
    "    target_size=shape_used,\n",
    "    batch_size=batch_size,\n",
    "    #class_mode=\"categorical\",\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.title(str(y_train[0]))\n",
    "# plt.imshow(x_train[0].reshape((224, 224)), cmap='gray')\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.title(str(y_valid[4]))\n",
    "# plt.imshow(x_valid[4].reshape((224, 224)), cmap='gray')\n",
    "\n",
    "# Build Model and Train\n",
    "\n",
    "#model = custom_model()\n",
    "model = mobilenet_model()\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('mobilenetEye.h5', monitor='val_loss',\n",
    "                             verbose=1, save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=n_patience, verbose=1)\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid_generator,\n",
    "                    workers=4,\n",
    "                    callbacks=[earlystop,checkpoint,tb_hist])\n",
    "\n",
    "model.save('models/train_mobileEye_%s.h5' %(epochs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 0.5])\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "scores = model.evaluate_generator(test_generator, steps=8)\n",
    "print(\"## evaluation ##\")\n",
    "print(scores)\n",
    "print(\"#################\")\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test,y_test, batch_size=32)\n",
    "print(\"## evaluation ##\")\n",
    "print(scores)\n",
    "print(\"#################\")\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=405)\n",
    "print(\"## evaluation ##\")\n",
    "print(scores)\n",
    "print(\"#################\")\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"## evaluation ##\")\n",
    "print(scores)\n",
    "print(\"#################\")\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=10)\n",
    "print(\"## evaluation ##\")\n",
    "print(scores)\n",
    "print(\"#################\")\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "#\n",
    "#model.fit_generator(\n",
    "#    train_generator, epochs=50, validation_data=valid_generator,\n",
    "#    callbacks=[\n",
    "#        ModelCheckpoint('models/%s.h5' % (start_time), monitor='valid_acc', save_best_only=True, mode='max', verbose=1),\n",
    "#        ReduceLROnPlateau(monitor='valid_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('models/train_mrl_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(‘train_mrl_0.hdf5’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history['loss'], history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "# model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "# y_pred = model.predict(x_val/255.)\n",
    "# y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "# print ('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "# cm = confusion_matrix(y_val, y_pred_logical)\n",
    "# sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.distplot(y_pred, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MobileNetV2(input_shape=(32, 32, 1), include_top=True, weights=None, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
